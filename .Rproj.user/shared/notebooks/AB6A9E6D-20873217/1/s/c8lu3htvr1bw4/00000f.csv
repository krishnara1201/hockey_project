"0","set.seed(42)"
"0","train_matrix <- model.matrix(as.formula(formula_full), data = dtrain)[,-1]  # Remove intercept"
"0","train_labels <- log(dtrain$salary)"
"0",""
"0","xgb_dtrain <- xgb.DMatrix(data = train_matrix, label = train_labels)"
"0",""
"0",""
"0","test_matrix <- model.matrix(as.formula(formula_full), data = dtest)[,-1]"
"0",""
"0","# Handle any missing features (set to 0)"
"0","missing_cols <- setdiff(colnames(train_matrix), colnames(test_matrix))"
"0","test_matrix <- cbind(test_matrix, matrix(0, nrow = nrow(test_matrix), "
"0","                                         ncol = length(missing_cols),"
"0","                                         dimnames = list(NULL, missing_cols)))"
"0",""
"0","# Ensure column order matches training data"
"0","test_matrix <- test_matrix[, colnames(train_matrix)]"
"0","xgb_dtest <- xgb.DMatrix(data = test_matrix)"
"0",""
"0","params <- list("
"0","  booster = ""gbtree"","
"0","  objective = ""reg:squarederror"","
"0","  eta = 0.1,"
"0","  max_depth = 6,"
"0","  subsample = 0.8,"
"0","  colsample_bytree = 0.9,"
"0","  gamma = 1"
"0",")"
"0",""
"0","set.seed(42)"
"0","xgb_cv <- xgb.cv("
"0","  params = params,"
"0","  data = xgb_dtrain,"
"0","  nrounds = 1000,"
"0","  nfold = 10,"
"0","  early_stopping_rounds = 35,"
"0","  print_every_n = 50"
"0",")"
"1","[1]	train-rmse:12.160169+0.009662	test-rmse:12.159526+0.091329"
"1"," "
"1","
"
"1","Multiple eval metrics are present. Will use "
"1",""
"1","test_rmse"
"1",""
"1"," for early stopping.
"
"1","Will train until "
"1",""
"1","test_rmse"
"1",""
"1"," hasn't improved in "
"1",""
"1","35"
"1",""
"1"," rounds.

"
"1","[51]	train-rmse:0.273642+0.004746	test-rmse:0.347639+0.042054"
"1"," "
"1","
"
"1","[101]	train-rmse:0.248162+0.004135	test-rmse:0.334158+0.043299"
"1"," "
"1","
"
"1","[151]	train-rmse:0.242831+0.004848	test-rmse:0.333260+0.042487"
"1"," "
"1","
"
"1","Stopping. Best iteration:
"
"1",""
"1","[117]	train-rmse:0.246387+0.003556	test-rmse:0.333057+0.042937"
"1",""
"1","

"
"0","# Train model"
"0","xgb_model <- xgb.train("
"0","  params = params,"
"0","  data = xgb_dtrain,"
"0","  nrounds = xgb_cv$best_iteration"
"0",")"
"0",""
"0","importance_matrix <- xgb.importance("
"0","  feature_names = colnames(train_matrix),"
"0","  model = xgb_model"
"0",")"
"0",""
"0","xgb.plot.importance(importance_matrix, top_n = 20)"
